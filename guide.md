# 主线目标

* 在已有 ROI（来自 RSVP/ThinkFirst）与初始掩码的基础上，**自动提出高质量正/负点**，驱动 SAM 的交互分割 **迭代收敛**（3 轮左右）。
* 通过把**子区域掩码**作为 **alpha 通道（软空间先验）**送入 CLIP/VLM，对“上一轮提示词给出的 instance 类别”做**语义可信度评分**，据此**选择正/负点**；若不确定则**对子区域再细分**，直到分清。
* 避免硬裁剪的语义错配，充分利用全图上下文（这正是 COCUS 用 alpha 通道的动机与收益点）。
* 正/负点的多轮“雕刻（sculpting）”符合 ArgusCogito 的**语言引导 + 点提示迭代**范式（k≈3）。

---

# 流程（ROI → 正/负点 → SAM 迭代）

## Step 0. 输入

* 图像 `I`；ROI（由 `ids_vertical/ids_horizontal` 回算的 BBox，四周加 \~20% padding）
* 初始掩码 `M0`（用 BBox 提示 SAM 得到）
* 文本类别 `T`（上一阶段输出的 `instance`）

  * 文本模板建议：`"a photo of the <T> camouflaged in the background."`（与 COCUS 语言分支一致）

## Step 1. ROI 网格化分块（可递归）

* 在 **BBox 内**对 `M0` 进行**规则分块**（初始 `3×3`，必要时递归 bisection/quadtree），得到格子集合 `{Cj}`。
* 对每个格子 `Cj`，构造 **子区域软先验掩码**：

  * `Aj = M0 ⊙ 1_{Cj}`（仅保留该格子内的掩码像素，其余置零）
  * 目的：让模型在**保持全局图像上下文**的同时，对**该子区域**进行“语义聚焦”的置信评分（软空间先验）。这避免了**硬裁剪**引起的 CLIP 语义域不匹配。

## Step 2. Alpha 软先验置信评分（每个子区域）

* **A 方案（最佳）**：使用 **COCUS/Alpha-CLIP 风格的 4 通道推理**

  * 输入三元组 `{I, Aj, T}` 给 **带 Alpha 分支的 CLIP**（或文中 fine-tuned 版本），输出视觉嵌入 `Ev` 与文本嵌入 `Et`，相似度 `Sj = Et·Ev` 作为该子区域属于 `T` 的置信度。

* **必要时的多文本增强**：为 `T` 增加 2–3 个同义模板（e.g., “<T> blending into surroundings”），取平均分。

## Step 3. 子区域判定 → 选点策略

* 统计所有格子的分数 `{Sj}`，计算均值 μ、标准差 σ。
* **阈值**（自适应，鲁棒）：

  * `τ_pos = μ + 0.5σ`（或 Top-30% 分位）
  * `τ_neg = μ - 0.5σ`（或 Bottom-30% 分位）
  * `τ_unc = [τ_neg, τ_pos]` 为“不确定带”。
* **正点（P⁺）生成**（每个 `Sj ≥ τ_pos` 的格子各取 1–2 个）：

  * 在 `Aj` 非零区域内，选**掩码骨架/质心**或**最大内接圆中心**处的像素；若有**边界弱化**，优先在**主体内部**落点，避免边界抖动。
* **负点（P⁻）生成**（每个 `Sj ≤ τ_neg` 的格子各取 1–2 个）：

  * 选 `Aj`≈0 的位置，**靠近当前掩码外溢边缘**（距 `M0` 边界 5–15px），更有信息增益。
* **不确定格（τ\_unc）**：进入 **Step 4 递归细分**（2×2 或 1×2/2×1），直至：

  * 子格尺寸 < `min_size`（如 32px），或
  * 子格 `S` 脱离不确定带，或
  * 达到 `max_depth`（如 2–3 层）。
* **点数上限**：每轮控制总点数 8–14 个；正:负≈2:1，避免负点过多导致“掐断”主体。

* 注：这种“**先评分再落点**”与 Argus 的 **sculpting** 思想一致（用语义信号挑选高价值点），随后交给 SAM 做**迭代雕刻**。

## Step 4. 用（P⁺, P⁻）提示 SAM → 新掩码 M₁

* 把上一部得到的**正/负点**作为 SAM 的交互提示，生成 `M1`。
* **早停与重采样**：

  * 若 `IoU(M1, M0)` 提升 < 0.5% 且 `|P⁺|<3`，对**最高分的正格**额外落 1 个点；若仍无改进，则结束本轮。
* **更新**：`M0 ← M1`。

## Step 5. 迭代（k ≈ 3）

* 重复 **Step 1–4** 共 **k=3** 轮（Argus 消融最优），直至早停。
* 每轮开始前可对 `M0` 做一次**细边缘平滑 + 小孔填补**（形态学开闭运算），提升后续评分稳定性。

## Step 6. 选择性增强（可插拔）

* **深度先验（推荐）**：若有深度 `D`，在子格打分时加入**深度一致性**（与当前 `M0` 内部中位深度偏差过大 → 倾向负/不确定），对伪装边界特别有效。
* **边界专向格**：在 `∂M0` 邻域动态抽取“边界格”，优先用于**负点**与**微调正点**，能快速抑制外溢或补边。
* **文本多粒度**：若 `T` 是“上位词”，可附加 1–2 个**下位关键部位短语**（如 “dorsal ridge of <T>”）做打分投票，提升对**核心部件**的定位。

---

# 关键设计的动机与依据

* **Alpha 软先验**：将“掩码（或子掩码）”作为 **alpha 通道**与 RGB 融合，再送入 CLIP，可在**保留全图上下文**的同时把注意力**聚焦至候选区域**，显著改善分类/语义打分的可靠性（避免硬裁剪域错配）。这是 COCUS 的核心思想之一，且实验显示分类与整体 OVCOS 性能显著提升。
* **Sculpting 迭代**：以**语义验证**驱动的**正/负点**，多轮引导 SAM 细化边界与抑制外溢，是 Argus 风格的“语言—视觉协同”要义，经验上 **k≈3** 最稳。&#x20;

---

# 超参与默认值（开箱即用）

* BBox padding：`0.2`
* 初始网格：`3×3`；`min_size=32px`；`max_depth=2`
* 阈值：`τ_pos=μ+0.5σ`，`τ_neg=μ-0.5σ`（或 30/70 分位）；不确定带为中间区间
* 每轮点数：`8–14`，正:负≈`2:1`
* 迭代轮次：`k=3`（早停）
* 文本模板：`"a photo of the <T> camouflaged in the background."`（+2 同义模板平均）

---

# 失败模式与对策

* **同质背景“全部高分”**：加入**背景对照**（把 Aj 置零的空格样本，作为分布基线），用 z-score/分位阈值而非固定阈值。
* **边界抖动**：优先在**主体内部**落正点；负点靠近“疑似外溢”边界外侧 5–15px。
* **多目标/黏连**：在 Step 2 的多模板中加入**部件短语**，用“核心部件子格”优先落正点，拆解连体。

---

# 产出与对接

* 每轮输出：`{P⁺, P⁻, M_t}` 与**格级评分图**（可视化热度图→调参直观）。
* 与你现有管线：\*\*直接替换“正/负点生成器”\*\*模块即可；SAM/SAM2 接口不变。
* 若你当前就有 COCUS 提供的 **Alpha-CLIP/4 通道 CLIP**，建议优先用 **A 方案**；否则先用 **B 方案**近似，后续再换回 A 方案以获得更稳定的打分与收敛。

---

如果你愿意，我可以把 **Step 2/3 的打分与选点**写成一个最小可运行的 Python 伪实现（接受 `I, M0, BBox, text`，批量导出 `{P⁺, P⁻}`），你把它插到你现有的 SAM 交互循环里就行。
