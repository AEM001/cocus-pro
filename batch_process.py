#!/usr/bin/env python3
"""
æ‰¹é‡å›¾åƒå¤„ç†è„šæœ¬
è‡ªåŠ¨å¤„ç†auxiliary/images/ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶

æ”¯æŒçš„åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å‘ç°å›¾åƒæ–‡ä»¶
2. æ‰¹é‡APIç›®æ ‡æ£€æµ‹
3. æ‰¹é‡SAMç²¾ä¿®
4. å¹¶è¡Œå¤„ç†æ”¯æŒ
5. é”™è¯¯å¤„ç†å’Œé‡è¯•
6. è¿›åº¦æ˜¾ç¤º
"""

import os
import sys
import argparse
import subprocess
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime
import glob

# æ”¯æŒçš„å›¾åƒæ ¼å¼
SUPPORTED_FORMATS = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif'}

# é»˜è®¤ç›®æ ‡æ£€æµ‹æŸ¥è¯¢æ˜ å°„
DEFAULT_TARGETS = {
    'f': 'find the camouflaged scorpionfish',
    'dog': 'find the camouflaged dog',
    'cat': 'find the camouflaged cat',
    'q': 'find the camouflaged animal',
    'person': 'find the camouflaged person',
    'person2': 'find the camouflaged person'
}

def get_image_files(image_dir: str) -> List[Tuple[str, str]]:
    """
    è·å–æ‰€æœ‰æ”¯æŒçš„å›¾åƒæ–‡ä»¶
    è¿”å›: [(æ–‡ä»¶å, å®Œæ•´è·¯å¾„)] åˆ—è¡¨
    """
    image_files = []
    for ext in SUPPORTED_FORMATS:
        pattern = os.path.join(image_dir, f"*{ext}")
        pattern_upper = os.path.join(image_dir, f"*{ext.upper()}")
        
        for file_path in glob.glob(pattern) + glob.glob(pattern_upper):
            name = os.path.splitext(os.path.basename(file_path))[0]
            image_files.append((name, file_path))
    
    return sorted(image_files)

def run_command_with_retry(cmd: str, description: str, max_retries: int = 2) -> Tuple[bool, str]:
    """
    è¿è¡Œå‘½ä»¤å¹¶é‡è¯•
    """
    for attempt in range(max_retries + 1):
        try:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {description}")
            if attempt > 0:
                print(f"  é‡è¯• {attempt}/{max_retries}")
            
            result = subprocess.run(
                cmd, shell=True, check=True,
                capture_output=True, text=True,
                cwd="/home/albert/code/CV"
            )
            
            return True, result.stdout
            
        except subprocess.CalledProcessError as e:
            error_msg = f"å‘½ä»¤å¤±è´¥: {e}\nè¾“å‡º: {e.stdout}\né”™è¯¯: {e.stderr}"
            
            if attempt < max_retries:
                print(f"  [WARN] {error_msg}")
                print(f"  ç­‰å¾…2ç§’åé‡è¯•...")
                time.sleep(2)
            else:
                print(f"  [ERROR] {error_msg}")
                return False, error_msg
    
    return False, "è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"

def process_single_image(name: str, image_path: str, args) -> Dict:
    """
    å¤„ç†å•ä¸ªå›¾åƒ
    """
    start_time = time.time()
    result = {
        'name': name,
        'image_path': image_path,
        'success': False,
        'error': None,
        'steps_completed': [],
        'processing_time': 0,
        'output_files': []
    }
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {name}")
        print(f"   è·¯å¾„: {image_path}")
        print(f"{'='*60}")
        
        # è®¾ç½®ç›®æ ‡æŸ¥è¯¢
        target_query = args.target or DEFAULT_TARGETS.get(name, f'find the camouflaged object in {name}')
        
        # æ„å»ºåŸºæœ¬å‘½ä»¤å‚æ•° - ç›´æ¥ä½¿ç”¨pythonè·¯å¾„
        python_path = "/home/albert/anaconda3/envs/camo-vlm/bin/python"
        base_env = f"export DASHSCOPE_API_KEY='{args.api_key}'"
        
        # æ­¥éª¤1ï¼šç”Ÿæˆç½‘æ ¼æ ‡æ³¨å›¾
        if not args.skip_grid:
            grid_cmd = f"""{base_env} && cd auxiliary/scripts && {python_path} make_region_prompts.py \\
                --name {name} \\
                --image ../images/{os.path.basename(image_path)} \\
                --rows {args.grid_size} \\
                --cols {args.grid_size}"""
            
            success, output = run_command_with_retry(grid_cmd, f"ç”Ÿæˆç½‘æ ¼æ ‡æ³¨å›¾", args.retry_count)
            if not success:
                result['error'] = f"ç½‘æ ¼ç”Ÿæˆå¤±è´¥: {output}"
                return result
            result['steps_completed'].append('grid_generation')
        
        # æ­¥éª¤2ï¼šAPIç›®æ ‡æ£€æµ‹
        if not args.skip_detection:
            detection_cmd = f"""{base_env} && cd auxiliary/scripts && {python_path} detect_target_api.py \\
                --name {name} \\
                --target "{target_query}" \\
                --model {args.api_model} \\
                --grid-size {args.grid_size}"""
            
            if args.use_openai_api:
                detection_cmd += " --use-openai"
            if args.high_resolution:
                detection_cmd += " --high-res"
            
            success, output = run_command_with_retry(detection_cmd, f"APIç›®æ ‡æ£€æµ‹", args.retry_count)
            if not success:
                result['error'] = f"ç›®æ ‡æ£€æµ‹å¤±è´¥: {output}"
                return result
            result['steps_completed'].append('target_detection')
        
        # æ­¥éª¤3ï¼šç”ŸæˆSAMè¾“å…¥
        if not args.skip_build:
            build_cmd = f"""{base_env} && {python_path} auxiliary/scripts/build_prior_and_boxes.py \\
                --name {name} \\
                --meta auxiliary/scripts/out/{name}/{name}_meta.json \\
                --pred auxiliary/llm_out/{name}_output.json"""
            
            success, output = run_command_with_retry(build_cmd, f"ç”ŸæˆSAMè¾“å…¥", args.retry_count)
            if not success:
                result['error'] = f"SAMè¾“å…¥ç”Ÿæˆå¤±è´¥: {output}"
                return result
            result['steps_completed'].append('sam_input_generation')
        
        # æ­¥éª¤4ï¼šSAMç²¾ä¿®
        if not args.skip_sculpt:
            sculpt_cmd = f"""{base_env} && {python_path} clean_sam_sculpt.py \\
                --name {name} \\
                --rounds {args.rounds} \\
                --ratio {args.ratio} \\
                --vlm_max_side {args.vlm_max_side} \\
                --output-format {args.output_format}"""
            
            # APIé€‰é¡¹
            if args.use_api:
                sculpt_cmd += f" --use-api --api-model {args.api_model}"
                if args.use_openai_api:
                    sculpt_cmd += " --use-openai-api"
                if args.high_resolution:
                    sculpt_cmd += " --high-resolution"
            
            # æ¸…ç†è¾“å‡ºé€‰é¡¹
            if args.clean_output:
                sculpt_cmd += " --clean-output"
            
            success, output = run_command_with_retry(sculpt_cmd, f"SAMç²¾ä¿®", args.retry_count)
            if not success:
                result['error'] = f"SAMç²¾ä¿®å¤±è´¥: {output}"
                return result
            result['steps_completed'].append('sam_sculpting')
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        output_dir = f"outputs/clean_sculpt/{name}"
        if os.path.exists(output_dir):
            output_files = os.listdir(output_dir)
            result['output_files'] = output_files
        
        result['success'] = True
        result['processing_time'] = time.time() - start_time
        
        print(f"âœ… {name} å¤„ç†å®Œæˆ! ç”¨æ—¶: {result['processing_time']:.1f}ç§’")
        
    except Exception as e:
        result['error'] = f"å¤„ç†å¼‚å¸¸: {str(e)}"
        result['processing_time'] = time.time() - start_time
        print(f"âŒ {name} å¤„ç†å¤±è´¥: {result['error']}")
    
    return result

def save_batch_report(results: List[Dict], output_dir: str):
    """ä¿å­˜æ‰¹å¤„ç†æŠ¥å‘Š"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_count = len(results)
    success_count = sum(1 for r in results if r['success'])
    failed_count = total_count - success_count
    total_time = sum(r['processing_time'] for r in results)
    avg_time = total_time / total_count if total_count > 0 else 0
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_images': total_count,
            'successful': success_count,
            'failed': failed_count,
            'success_rate': success_count / total_count * 100 if total_count > 0 else 0,
            'total_processing_time': total_time,
            'average_processing_time': avg_time
        },
        'results': results
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    report_path = os.path.join(output_dir, f'batch_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š
    txt_report_path = os.path.join(output_dir, f'batch_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt')
    with open(txt_report_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("æ‰¹é‡å¤„ç†æŠ¥å‘Š\n")
        f.write("="*60 + "\n")
        f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å›¾åƒæ•°: {total_count}\n")
        f.write(f"æˆåŠŸ: {success_count}\n")
        f.write(f"å¤±è´¥: {failed_count}\n")
        f.write(f"æˆåŠŸç‡: {success_count / total_count * 100:.1f}%\n")
        f.write(f"æ€»å¤„ç†æ—¶é—´: {total_time:.1f}ç§’\n")
        f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.1f}ç§’/å›¾åƒ\n\n")
        
        # æˆåŠŸçš„å›¾åƒ
        if success_count > 0:
            f.write("æˆåŠŸå¤„ç†çš„å›¾åƒ:\n")
            f.write("-" * 40 + "\n")
            for result in results:
                if result['success']:
                    f.write(f"âœ… {result['name']} ({result['processing_time']:.1f}s)\n")
                    f.write(f"   è¾“å‡ºæ–‡ä»¶: {', '.join(result['output_files'])}\n")
        
        # å¤±è´¥çš„å›¾åƒ
        if failed_count > 0:
            f.write(f"\nå¤±è´¥çš„å›¾åƒ:\n")
            f.write("-" * 40 + "\n")
            for result in results:
                if not result['success']:
                    f.write(f"âŒ {result['name']}: {result['error']}\n")
    
    print(f"\nğŸ“Š æ‰¹å¤„ç†æŠ¥å‘Šå·²ä¿å­˜:")
    print(f"   JSONæŠ¥å‘Š: {report_path}")
    print(f"   æ–‡æœ¬æ‘˜è¦: {txt_report_path}")

def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡å¤„ç†å›¾åƒæ–‡ä»¶")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--image-dir', default='auxiliary/images', help='å›¾åƒæ–‡ä»¶ç›®å½•')
    parser.add_argument('--include', nargs='+', help='åªå¤„ç†æŒ‡å®šçš„å›¾åƒåç§° (ä¸å«æ‰©å±•å)')
    parser.add_argument('--exclude', nargs='+', help='æ’é™¤æŒ‡å®šçš„å›¾åƒåç§° (ä¸å«æ‰©å±•å)')
    parser.add_argument('--target', help='ç»Ÿä¸€çš„ç›®æ ‡æ£€æµ‹æŸ¥è¯¢ï¼Œè¦†ç›–é»˜è®¤æ˜ å°„')
    
    # APIå‚æ•°
    parser.add_argument('--api-key', help='APIå¯†é’¥ (é»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–)')
    parser.add_argument('--api-model', default='qwen-vl-plus-latest', help='APIæ¨¡å‹åç§°')
    parser.add_argument('--use-api', action='store_true', help='ä½¿ç”¨APIæ¨¡å¼')
    parser.add_argument('--use-openai-api', action='store_true', help='ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼')
    parser.add_argument('--high-resolution', action='store_true', help='å¯ç”¨é«˜åˆ†è¾¨ç‡æ¨¡å¼')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--grid-size', type=int, default=9, help='ç½‘æ ¼å¤§å°')
    parser.add_argument('--rounds', type=int, default=1, help='SAMç²¾ä¿®è½®æ•°')
    parser.add_argument('--ratio', type=float, default=0.6, help='è±¡é™æ¯”ä¾‹')
    parser.add_argument('--vlm-max-side', type=int, default=720, help='VLMè¾“å…¥å›¾åƒæœ€å¤§è¾¹é•¿')
    parser.add_argument('--output-format', choices=['png', 'jpg'], default='png', help='è¾“å‡ºæ©ç æ ¼å¼')
    parser.add_argument('--clean-output', action='store_true', help='åªä¿ç•™æœ€ç»ˆæ©ç å’Œinstanceä¿¡æ¯')
    
    # æ‰¹å¤„ç†å‚æ•°
    parser.add_argument('--parallel', type=int, default=1, help='å¹¶è¡Œå¤„ç†æ•° (1=ä¸²è¡Œ)')
    parser.add_argument('--retry-count', type=int, default=2, help='å¤±è´¥é‡è¯•æ¬¡æ•°')
    parser.add_argument('--report-dir', default='batch_reports', help='æŠ¥å‘Šä¿å­˜ç›®å½•')
    
    # è·³è¿‡æ­¥éª¤é€‰é¡¹
    parser.add_argument('--skip-grid', action='store_true', help='è·³è¿‡ç½‘æ ¼ç”Ÿæˆ')
    parser.add_argument('--skip-detection', action='store_true', help='è·³è¿‡ç›®æ ‡æ£€æµ‹')
    parser.add_argument('--skip-build', action='store_true', help='è·³è¿‡SAMè¾“å…¥ç”Ÿæˆ')
    parser.add_argument('--skip-sculpt', action='store_true', help='è·³è¿‡SAMç²¾ä¿®')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸš€ æ‰¹é‡å›¾åƒå¤„ç†ç³»ç»Ÿ")
    print("="*60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not args.api_key:
        args.api_key = os.getenv('DASHSCOPE_API_KEY')
        if not args.api_key:
            print("[ERROR] éœ€è¦è®¾ç½®APIå¯†é’¥")
            print("ä½¿ç”¨ --api-key å‚æ•°æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
            return 1
    
    print(f"APIå¯†é’¥: {args.api_key[:8]}...")
    print(f"APIæ¨¡å‹: {args.api_model}")
    
    # è·å–å›¾åƒæ–‡ä»¶
    image_files = get_image_files(args.image_dir)
    if not image_files:
        print(f"[ERROR] åœ¨ {args.image_dir} ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„å›¾åƒæ–‡ä»¶")
        print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_FORMATS)}")
        return 1
    
    # è¿‡æ»¤å›¾åƒæ–‡ä»¶
    if args.include:
        image_files = [(name, path) for name, path in image_files if name in args.include]
        print(f"åŒ…å«è¿‡æ»¤: {args.include}")
    
    if args.exclude:
        image_files = [(name, path) for name, path in image_files if name not in args.exclude]
        print(f"æ’é™¤è¿‡æ»¤: {args.exclude}")
    
    if not image_files:
        print("[ERROR] è¿‡æ»¤åæ²¡æœ‰å›¾åƒæ–‡ä»¶éœ€è¦å¤„ç†")
        return 1
    
    print(f"å¾…å¤„ç†å›¾åƒ: {len(image_files)}")
    for name, path in image_files:
        print(f"  - {name}")
    
    print(f"å¤„ç†æ¨¡å¼: {'API' if args.use_api else 'æœ¬åœ°'}")
    print(f"å¹¶è¡Œæ•°: {args.parallel}")
    print(f"æ¸…ç†è¾“å‡º: {'æ˜¯' if args.clean_output else 'å¦'}")
    
    # å¼€å§‹æ‰¹å¤„ç†
    start_time = time.time()
    results = []
    
    if args.parallel == 1:
        # ä¸²è¡Œå¤„ç†
        for i, (name, image_path) in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] å¤„ç† {name}...")
            result = process_single_image(name, image_path, args)
            results.append(result)
    else:
        # å¹¶è¡Œå¤„ç†
        print(f"\nå¼€å§‹å¹¶è¡Œå¤„ç† (å¹¶å‘æ•°: {args.parallel})...")
        
        with ThreadPoolExecutor(max_workers=args.parallel) as executor:
            # æäº¤ä»»åŠ¡
            future_to_name = {}
            for name, image_path in image_files:
                future = executor.submit(process_single_image, name, image_path, args)
                future_to_name[future] = name
            
            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_name):
                completed += 1
                name = future_to_name[future]
                try:
                    result = future.result()
                    results.append(result)
                    print(f"[{completed}/{len(image_files)}] {name} å®Œæˆ")
                except Exception as e:
                    error_result = {
                        'name': name,
                        'success': False,
                        'error': f"å¹¶è¡Œå¤„ç†å¼‚å¸¸: {str(e)}",
                        'processing_time': 0,
                        'steps_completed': [],
                        'output_files': []
                    }
                    results.append(error_result)
                    print(f"[{completed}/{len(image_files)}] {name} å¼‚å¸¸: {e}")
    
    # ç»Ÿè®¡ç»“æœ
    total_time = time.time() - start_time
    success_count = sum(1 for r in results if r['success'])
    failed_count = len(results) - success_count
    
    print("\n" + "="*60)
    print("ğŸ“Š æ‰¹å¤„ç†å®Œæˆ!")
    print("="*60)
    print(f"æ€»å¤„ç†æ—¶é—´: {total_time:.1f}ç§’")
    print(f"æˆåŠŸ: {success_count}/{len(results)}")
    print(f"å¤±è´¥: {failed_count}/{len(results)}")
    print(f"æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
    
    # ä¿å­˜æŠ¥å‘Š
    save_batch_report(results, args.report_dir)
    
    # æ˜¾ç¤ºå¤±è´¥çš„å›¾åƒ
    if failed_count > 0:
        print(f"\nâŒ å¤±è´¥çš„å›¾åƒ:")
        for result in results:
            if not result['success']:
                print(f"  - {result['name']}: {result['error']}")
    
    return 0 if failed_count == 0 else 1

if __name__ == "__main__":
    exit(main())