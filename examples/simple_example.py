#!/usr/bin/env python3
"""
CVè¯­ä¹‰åˆ†å‰²ç®¡é“ç®€å•ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨Alpha-CLIPå’ŒSAMè¿›è¡Œè¯­ä¹‰å¼•å¯¼çš„å›¾åƒåˆ†å‰²ã€‚
"""

import os
import sys
import numpy as np
from PIL import Image
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def main():
    print("ğŸš€ CVè¯­ä¹‰åˆ†å‰²ç®¡é“ç¤ºä¾‹")
    print("=" * 50)
    
    # æ£€æŸ¥æµ‹è¯•å›¾åƒæ˜¯å¦å­˜åœ¨
    test_image_path = "auxiliary/images/q.png"
    if not os.path.exists(test_image_path):
        print(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image_path}")
        print("è¯·ç¡®ä¿auxiliary/data/images/ç›®å½•ä¸‹æœ‰æµ‹è¯•å›¾åƒ")
        return
    
    try:
        # 1. åŠ è½½å›¾åƒ
        print("\nğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ...")
        image = np.array(Image.open(test_image_path))
        print(f"   åŸå§‹å›¾åƒå°ºå¯¸: {image.shape}")

        # ä¸ºSAMè°ƒæ•´å›¾åƒå°ºå¯¸ï¼ˆé•¿è¾¹ä¸è¶…è¿‡1024ï¼‰
        if len(image.shape) == 3 and image.shape[2] == 4:
            # å¦‚æœæ˜¯RGBAï¼Œè½¬æ¢ä¸ºRGB
            image_rgb = image[:, :, :3]
        else:
            image_rgb = image

        # è°ƒæ•´å°ºå¯¸ä»¥é€‚é…SAM
        from PIL import Image as PILImage
        pil_img = PILImage.fromarray(image_rgb)
        w, h = pil_img.size
        max_side = max(w, h)
        if max_side > 1024:
            scale = 1024 / max_side
            new_w, new_h = int(w * scale), int(h * scale)
            pil_img = pil_img.resize((new_w, new_h), PILImage.LANCZOS)
            image_for_sam = np.array(pil_img)
        else:
            image_for_sam = image_rgb

        print(f"   SAMå¤„ç†åå°ºå¯¸: {image_for_sam.shape}")

        # ä¿æŒåŸå§‹å›¾åƒç”¨äºAlpha-CLIP
        image = image_rgb
        
        # 2. åˆå§‹åŒ–Alpha-CLIPæ¨¡å‹
        print("\nğŸ¯ åˆå§‹åŒ–Alpha-CLIPæ¨¡å‹ï¼ˆå¼ºåˆ¶ Alpha åˆ†æ”¯æƒé‡ï¼‰...")
        from alpha_clip_rw import AlphaCLIPInference
        try:
            alpha_clip = AlphaCLIPInference(
                model_name="ViT-L/14@336px",
                alpha_vision_ckpt_pth="AUTO",  # ä» env æˆ– checkpoints/ è‡ªåŠ¨æŸ¥æ‰¾
                device="cpu"
            )
            print("   âœ“ Alpha-CLIPæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ Alpha-CLIPåŠ è½½å¤±è´¥: {e}")
            print("   è¯·å°† Alpha-CLIP è§†è§‰åˆ†æ”¯æƒé‡æ”¾åœ¨ checkpoints/clip_l14_336_grit_20m_4xe.pthï¼Œ"
                  "æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ ALPHA_CLIP_ALPHA_CKPT åé‡è¯•ã€‚")
            return
        
        # 3. åˆå§‹åŒ–SAMæ¨¡å‹
        print("\nğŸ”§ åˆå§‹åŒ–SAMæ¨¡å‹ï¼ˆéœ€è¦æœ¬åœ°æƒé‡ï¼‰...")
        from sam_integration import create_sam_wrapper
        sam_ckpt = "models/sam_vit_h_4b8939.pth"
        if not os.path.isfile(sam_ckpt):
            print(f"   âŒ æœªæ‰¾åˆ° SAM æƒé‡: {sam_ckpt}")
            print("   è¯·ä¸‹è½½ sam_vit_h_4b8939.pth åˆ° models/ ç›®å½•åé‡è¯•ã€‚")
            return
        sam_wrapper = create_sam_wrapper(
            model_type="sam",
            checkpoint_path=sam_ckpt
        )
        print("   âœ“ SAMæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # 4. æ¼”ç¤ºAlpha-CLIPè¯­ä¹‰è¯„åˆ†
        if alpha_clip:
            print("\nğŸ§  æ¼”ç¤ºAlpha-CLIPè¯­ä¹‰è¯„åˆ†...")
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ©ç 
            H, W = image.shape[:2]
            test_alpha = np.zeros((H, W), dtype=np.float32)
            test_alpha[H//4:3*H//4, W//4:3*W//4] = 1.0  # ä¸­å¿ƒåŒºåŸŸ
            
            # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
            score = alpha_clip.score_region_with_templates(
                image=image,
                alpha=test_alpha,
                instance_text="blurred person standing in field",
                templates=[
                    "a photo of the {} camouflaged in the background.",
                    "a photo of the {}.",
                    "the {} in the scene."
                ]
            )
            
            print(f"   è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æ•°: {score:.4f}")
            
            # æµ‹è¯•ä¸åŒåŒºåŸŸçš„è¯„åˆ†
            print("   æµ‹è¯•ä¸åŒåŒºåŸŸçš„è¯­ä¹‰è¯„åˆ†:")
            regions = [
                ("å·¦ä¸Šè§’", test_alpha * 0, [0, H//2, 0, W//2]),
                ("ä¸­å¿ƒåŒºåŸŸ", test_alpha, [H//4, 3*H//4, W//4, 3*W//4]),
                ("å³ä¸‹è§’", test_alpha * 0, [H//2, H, W//2, W])
            ]
            
            for name, alpha_region, bbox in regions:
                alpha_mask = np.zeros_like(test_alpha)
                alpha_mask[bbox[0]:bbox[1], bbox[2]:bbox[3]] = 1.0
                
                score = alpha_clip.score_region_with_templates(
                    image=image, 
                    alpha=alpha_mask, 
                    instance_text="blurred person standing in field"
                )
                print(f"     {name}: {score:.4f}")
        
        # 5. æ¼”ç¤ºè¯­ä¹‰å¼•å¯¼SAMï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰
        if alpha_clip and sam_wrapper:
            print("\nğŸ¨ æ¼”ç¤ºè¯­ä¹‰å¼•å¯¼SAMåˆ†å‰²...")
            
            from sam_integration import SemanticGuidedSAM
            
            # åˆ›å»ºè¯­ä¹‰å¼•å¯¼SAM
            semantic_sam = SemanticGuidedSAM(sam_wrapper, alpha_clip)
            
            # å®šä¹‰æµ‹è¯•è¾¹ç•Œæ¡† - åŸºäºè°ƒæ•´åçš„å›¾åƒ
            H_sam, W_sam = image_for_sam.shape[:2]
            bbox = [W_sam//4, H_sam//4, 3*W_sam//4, 3*H_sam//4]  # [x1, y1, x2, y2]
            
            # è¿è¡Œè¯­ä¹‰åˆ†å‰² - ä½¿ç”¨è°ƒæ•´åçš„å›¾åƒ
            result_mask = semantic_sam.segment_with_semantic_points(
                image=image_for_sam,
                bbox=bbox,
                instance_text="",
                grid_size=(2, 2),  # ç®€åŒ–ç½‘æ ¼
                max_points=8,
                iterations=2
            )
            
            print(f"   ç”Ÿæˆæ©ç å°ºå¯¸: {result_mask.shape}")
            print(f"   æ©ç è¦†ç›–ç‡: {result_mask.sum() / result_mask.size * 100:.1f}%")
            
            # ä¿å­˜ç»“æœ
            output_dir = Path("examples/output")
            output_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜æ©ç 
            Image.fromarray((result_mask * 255).astype(np.uint8)).save(
                output_dir / "semantic_mask.png"
            )
            
            # ä¿å­˜å¯è§†åŒ–å åŠ  - ä½¿ç”¨è°ƒæ•´åçš„å›¾åƒ
            overlay = image_for_sam.copy()
            overlay[result_mask > 0] = (
                overlay[result_mask > 0] * 0.7 +
                np.array([0, 255, 0], dtype=np.uint8) * 0.3
            ).astype(np.uint8)
            Image.fromarray(overlay).save(output_dir / "semantic_overlay.png")
            
            print(f"   ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        # 6. æ¼”ç¤ºCog-Sculptæ ¸å¿ƒAPI
        print("\nâš™ï¸ æ¼”ç¤ºCog-Sculptæ ¸å¿ƒAPI...")
        
        from cog_sculpt.core import (
            Config, Box, DensityScorer, 
            partition_grid, threshold_cells
        )
        
        # åˆ›å»ºé…ç½®
        config = Config(
            grid_init=(2, 2),
            k_iters=2,
            max_points_per_iter=6
        )
        
        # åˆ›å»ºæµ‹è¯•è¾¹ç•Œæ¡†
        bbox = Box(r0=H//4, c0=W//4, r1=3*H//4, c1=3*W//4)
        
        # ç½‘æ ¼åŒ–
        cells = partition_grid(bbox, config.grid_init)
        print(f"   ç”Ÿæˆç½‘æ ¼å•å…ƒæ•°: {len(cells)}")
        
        # æ¨¡æ‹Ÿè¯„åˆ†
        scorer = DensityScorer()
        test_mask = np.ones((H, W), dtype=np.uint8)
        test_mask[H//3:2*H//3, W//3:2*W//3] = 0  # åˆ›å»ºæ´
        
        for cell in cells:
            b = cell.box
            alpha = np.zeros_like(test_mask, dtype=np.float32)
            alpha[b.r0:b.r1, b.c0:b.c1] = test_mask[b.r0:b.r1, b.c0:b.c1]
            cell.score = scorer.score(image, alpha, "test")
        
        # é˜ˆå€¼åˆ†ç±»
        pos_cells, neg_cells, unc_cells = threshold_cells(cells)
        print(f"   æ­£ä¾‹ç½‘æ ¼: {len(pos_cells)}, è´Ÿä¾‹ç½‘æ ¼: {len(neg_cells)}, ä¸ç¡®å®š: {len(unc_cells)}")
        
        print("\nâœ… ç¤ºä¾‹æ¼”ç¤ºå®Œæˆ!")
        
        # ç”Ÿæˆæ€»ç»“
        print("\nğŸ“‹ åŠŸèƒ½æ€»ç»“:")
        print("   âœ“ å›¾åƒåŠ è½½å’Œé¢„å¤„ç†")
        if alpha_clip:
            print("   âœ“ Alpha-CLIPè¯­ä¹‰è¯„åˆ†")
        if alpha_clip and sam_wrapper:
            print("   âœ“ è¯­ä¹‰å¼•å¯¼SAMåˆ†å‰²")
        print("   âœ“ Cog-Sculptæ ¸å¿ƒç®—æ³•")
        print("\nğŸ”— æ›´å¤šç”¨æ³•è¯·å‚è€ƒdocs/USAGE.md")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
